#!/bin/python

import argparse
import requests
import sys
import os
import datetime
import urllib.request
from typing import Union
from datetime import datetime

class ApiKeyFile:
    def __init__(self):
        self.filename = os.path.expanduser("~/.tgpt/api")
        self.api_key = None
        
    def get_api_key(self):
        if self.api_key is None:
            with open(self.filename, 'r') as f:
                self.api_key = f.read().strip()
        return self.api_key

class ImageHandler:   
    def __init__(self, api_key):
        self.api_key = api_key
        self.endpoint_generation = "https://api.openai.com/v1/images/generations"
        self.endpoint_variation = "https://api.openai.com/v1/images/variations"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}"
        }
        self.image_sizes = {"small": "256x256", "medium": "512x512", "large": "1024x1024"}

    def _send_request(self, endpoint, data, files=None):
        headers = self.headers.copy()
        headers["Content-Type"] = "application/json"
        response = requests.post(endpoint, headers=headers, json=data, files=files)
        response.raise_for_status()
        return response.json()["data"]

    def generate_image(self, prompt, size="medium", n=1, response_format="url"):
        data = {
            "model": "image-alpha-001",
            "prompt": prompt,
            "size": self.image_sizes[size],
            "n": n,
            "response_format": response_format,
        }
        return self._send_request(self.endpoint_generation, data)

    def generate_variation(self, image_path, n=1, size="medium", response_format="url"):
        with open(image_path, 'rb') as image_file:
            data = {
                "n": n,
                "size": self.image_sizes[size],
                "response_format": response_format,        
            }
            files = {"image": image_file}
            headers = self.headers.copy()
            response = requests.post(self.endpoint_variation, headers=headers, data=data, files=files)
            response.raise_for_status()
            return response.json()["data"]


    def generate_variation(self, image_path, n=1, size="medium", response_format="url"):
        if isinstance(image_path, str):
            image_file = open(image_path, 'rb')

        data = {
            "n": n,
            "size": self.image_sizes[size],
            "response_format": response_format,        
        }
        files = {"image": image_file}

        response = requests.post(self.endpoint_variation, data=data, files=files, headers=self.headers)
        response.raise_for_status()

        return response.json()["data"]

class GPTClient:
    def __init__(self, api_key, model="gpt-3.5-turbo"):
        self.api_key = api_key
        self.endpoint_completions = "https://api.openai.com/v1/chat/completions"
        self.model = model
        self.chat_history = []
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"}
        self.image_handler = ImageHandler(self.api_key)

    def completion(self, prompt, n=1, max_tokens=100, temperature=0.7, top_p=1, frequency_penalty=0, presence_penalty=0, stop=None):
        payload = {
            "model": self.model,
            "messages": [],
            "max_tokens": max_tokens,
            "temperature": temperature,
            "top_p": top_p,
            "frequency_penalty": frequency_penalty,
            "presence_penalty": presence_penalty,
            "n": n,
            "stop": stop
        }

        if self.chat_history:
            history = self.chat_history
            history.append({"role": "user", "content": prompt})
            payload["messages"] = history
        else:
            payload["messages"] = [{"role": "user", "content": prompt}]
        
        response = requests.post(self.endpoint_completions, headers=self.headers, json=payload)
        response.raise_for_status()

        result = response.json()
        text = [choice['message']['content'] for choice in result['choices']]
        self.add_to_chat_history(prompt, text)
        return text

    def add_to_chat_history(self, prompt, response):
        prompt_message = {'role': 'user', 'content': prompt}
        
        if isinstance(response, list):
            response = response[0]  # Only store the first response in the chat history

        response_message = {'role': 'assistant', 'content': response}
        self.chat_history.append(prompt_message)
        self.chat_history.append(response_message)

    def get_chat_history(self):
        return self.chat_history

    def generate_image(self, prompt, size="medium", n=1, response_format="url"):
        return self.image_handler.generate_image(prompt, n=n, response_format=response_format, size=size)

    def generate_variation(self, image_path: str, n: int = 1, size="medium", response_format: str = "url") -> Union[str, bytes]:
        return self.image_handler.generate_variation(image_path, n=n, size=size, response_format=response_format)

    
class CommandLineInterface:
    def __init__(self, client):
        self.client = client

    def run(self):
        print("Welcome to TerminalGPT!")
        print("Type '/exit or /quit' to end the session.")

        while True:
            user_input = input("\nYou: ")
            if user_input.strip() == "":
                continue
            if user_input.startswith("/"):
                if not self.handle_command(user_input):
                    break
            else:
                response = self.client.completion(user_input)
                print(response[0])  # Only print the first response


    def handle_completion(self, prompt, n=1, temperature=0.7, max_tokens=100):
        if not prompt:
            return ""

        response = self.client.completion(prompt, n=n, temperature=temperature, max_tokens=max_tokens, stop=None)

        # Make sure the response is a list of strings
        if not isinstance(response, list):
            response = [response]

        for i, completion in enumerate(response):
            print(f"\nAnswer {i+1}:")
            print(f"\n{completion}")
        print("\n")

        return True

    def handle_command(self, command):
        if command in ("/exit", "/quit"):
            sys.exit(print("Goodbye!"))
        elif command == "/help":
            return self._print_help()
        elif command == "/temperature":
            temp = float(input("New temperature: "))
            self.client.temperature = temp
            print(f"Temperature set to {temp}")
            return True
        elif command == "/max-tokens":
            tokens = int(input("New max tokens: "))
            self.client.max_tokens = tokens
            print(f"Max tokens set to {tokens}")
            return True
        else:
            print("Invalid command, please use one of the following:")
            return self._print_help()

    def generate_image(self, prompt, n=1, size="medium", response_format="url"):
        response = self.client.generate_image(prompt=prompt, n=n, size=size, response_format=response_format)
        timestamp = datetime.now().strftime("%Y:%m:%d-%H:%M:%S")

        for i, image_url in enumerate(response):
            self.save_image(image_url, os.path.expanduser(f"~/Pictures/TerminalGPT/gpt-generate-{i}-{timestamp}.png"))

        return True

    def generate_variation(self, image_path, size="medium", n=1, response_format="url"):
        response = self.client.generate_variation(image_path=image_path, size=size, n=n, response_format=response_format)
        timestamp = datetime.now().strftime("%Y:%m:%d-%H:%M:%S")

        for i, image_url in enumerate(response):
            self.save_image(image_url, os.path.expanduser(f"~/Pictures/TerminalGPT/gpt-variation-{i}-{timestamp}.png"))

        return True

    def save_image(self, url, file_path, timeout=30):
        with urllib.request.urlopen(url['url'], timeout=timeout) as response, open(file_path, 'wb') as out_file:
            out_file.write(response.read())
        print(f"Saved image to {file_path}")

    def _print_help(self):
        print("Available commands:")
        print("/exit or /quit: Exit the program")
        print("/temperature: set new temperature")
        print("/max-tokens: set new max tokens")
        print("/help: Show this help message")


def main():
    # Create an ArgumentParser object to handle command line arguments
    parser = argparse.ArgumentParser()
    parser.add_argument("question", nargs="?", help="Text query")
    parser.add_argument("-c", "--chat", action="store_true", help="Enter chat mode")
    parser.add_argument("-gi", "--generate-image", metavar="PROMPT", help="Generate an image based on the given text prompt")
    parser.add_argument("-gv", "--generate-variation", metavar="EXISTING_IMAGE_PATH", help="Generate a variation of an existing image. Provide the path to the existing image as an argument.")
    parser.add_argument("-n", "--number", type=int, default=1, help="The number of images to generate or vary. Default is 1.")
    parser.add_argument("-t", "--temperature", metavar="TEMPERATURE", type=float, default=0.7, help="The temperature to use for generation (default: 0.5)")
    parser.add_argument("-m", "--max", type=int, default=100, help="The maximum number of tokens to generate for completions(Default: 100)")
    parser.add_argument("-s", "--size", choices=["small", "medium", "large"], default="medium", help="Image size")
    args = parser.parse_args()

    # Load API key from file
    api_key_file = ApiKeyFile()
    api_key = api_key_file.get_api_key()

    # Create client and command line interface objects
    client = GPTClient(api_key, "gpt-3.5-turbo")
    cli = CommandLineInterface(client)

    # Check if a question was provided as an argument
    if args.question:
        print("Sending query...")
        response = cli.handle_completion(args.question, n=args.number, temperature=args.temperature, max_tokens=args.max)

    # Check if chat mode was specified
    elif args.chat:
        cli.run()

    # Check if generate image mode was specified
    elif args.generate_image:
        print("Generating image...")
        image_data = cli.generate_image(args.generate_image, n=args.number, size=args.size)

    # Check if generate variation mode was specified
    elif args.generate_variation:
        print("Creating image variation...")
        image_path = args.generate_variation
        image_data = cli.generate_variation(image_path, n=args.number, size=args.size)

    # Print help message if no arguments are provided
    else:
        parser.print_help()


if __name__ == "__main__":
    main()

